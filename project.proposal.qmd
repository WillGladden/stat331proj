---
title: "The Clean and the Green"
subtitle: "Investigating the Relationship Between Income and Sanitation"
author: "Giovani Thai, William Gladden, Soren Paetau"
format: 
  html:
    self-contained: true
    code-tools: true
    code-fold: true
    toc: true
    number-sections: true
    smooth-scroll: true
    theme: minty
editor: source
execute: 
  error: true
  echo: true
  message: false
  warning: false
---

```{r setup}
library(tidyverse)
library(broom)
library(ggridges)
library(RColorBrewer)
library(knitr)
library(DT)
library(kableExtra)
library(gganimate)
library(gifski)
```

# Introduction
```{r import}

sanitation.data <- read_csv("at_least_basic_sanitation_overall_access_percent.csv")
income.data <- read_csv("income_per_person_gdppercapita_ppp_inflation_adjusted.csv")
colnames(income.data) <- c("country", as.numeric(1799:2049))
```

We are interested in the relationship between income and sanitation levels. One might assume that as income per person increases, so too will the access to basic necessities, including hygienic products and facilities, such as bathrooms and showers. We aim to analyze data relating to these factors, outlined in the process below.

```{r}
income.data |>
  slice_head(n = 1000) |>
  select(country, `1999`:`2002`) |>
  datatable(class = "cell-border",
            rownames = FALSE,
            caption = "Table 1: Preview of Income Data Set, 1999-2003.",
            filter = "top")
```
Our income data set measures the total GDP of a country per person for 216 countries between the years of 1892 and 2049, with units in fixed 2017 prices. This number is adjusted for PPP, or the differences between costs of living and essential products, across countries. The data comes from the World Bank, the Maddison Project Database, and the Penn World Table. Historical estimates were used for early years; forecasts from the IMF's Economic Outlook were used to project income in the future.

Source: <https://www.gapminder.org/data/documentation/gd001/>

### Sanitation  Dataset
```{r}
sanitation.data |>
  slice_head(n = 1000) |>
  select(1:5) |>
  datatable(class = "cell-border",
            rownames = FALSE,
            caption = "Table 2: Preview of Sanitation Data Set, 1999-2002.",
            filter = "top")
```
Our sanitation data set measures the percentage of people (living in both urban and rural settings) who use at lease basic sanitation services not shared with other households. This includes:

+ flushing/pouring to piped sewer systems
+ septic
+ ventilation for pit latrines (e.g. squat toilets)

The data was collected by the World Health Organization and UNICEF, falling between the years of 1999 to 2019.

Source: <https://data.worldbank.org/indicator/SH.STA.SMSS.ZS>

## Hypothesized Relationship
We hypothesize that there will be a positive relation between income per person and percentage of people with basic sanitation at their disposal. We would also like to investigate and highlight any potential outliers, such as moments in time where certain countries failed to improve sanitation with increased income, or drastic dips/surges in income/sanitation over a single year.


## Data Cleaning Process
```{r cleaning}
convert_num <- function(x){ #converts "12.3k" to 12300,  
  temp <- x
  if(str_detect(x, "k$")){
    temp <- x |> 
      str_replace_all("[^[:digit:]]", "") |> #gross but it just replaces any non-number with ""
      as.numeric() * 100
  }
  return(temp)
}

#data cleaning + joining
sanitation.clean <- sanitation.data |>
  drop_na() |>
  pivot_longer(cols = `1999`:`2019`,
               names_to = "year",
               values_to = "sanitation")

income.clean <- income.data |>
  drop_na() |> #pretty bold step to remove any rows with na vals, 
               #but due to the abundance of data seems reasonable
  select(c(country, `1999`:`2019`)) |>
  pivot_longer(cols = `1999`:`2019`,
               names_to = "year",
               values_to = "income") |>
  mutate(income = as.numeric(map(income, convert_num)))#converts characters,
  #able to convert after pivot, b/c data is all seen as strings!
```
The cleaning process above is relatively simple, converting some data entries of the form $12.3k \to 12300$. Notice that the decision to drop NA values was made, since `ggplot` and `lm` will drop NA values and we have an abundance of data entries. This decision will save headaches later down the road when taking advantage of the country column.

```{r join}
full.data <- inner_join(sanitation.clean, income.clean) |>
  mutate(year = as.numeric(year))

full.data |>
  slice_head(n = 1000) |>
  datatable(class = "cell-border",
            rownames = FALSE,
            caption = "Table 1: Preview of Data Set.",
            filter = "top")
```

# Linear Regression
We aim to piece together the relationship between income and sanitation levels.

## Data Visualization
Our goal is to develop a model that predicts the **percent of people with basic sanitation** (response) from **adjusted income per person** (explanatory).

### Macro-Scale Relation Between Income, Sanitation
We first visualize the relation between these two variables:

```{r relation}
data.plot <- full.data |>
  ggplot(mapping = aes(x = income, y = sanitation) ) +
  geom_jitter(alpha = 0.5) +
  geom_smooth(method = lm, level = 0, color = "red") +
  scale_y_continuous(limits = c(0,100),
                     breaks = seq(0,100,25)) +
  labs(title = "Income versus Sanitation, 1999-2019",
       subtitle = "Percentage of People with (at least) Basic Sanitation Services",
       x = "Adjusted Income per Person (in 2017 $)",
       y = "") 

data.plot

#data.plot + transition_time(year) +
#  labs(title = "Year: {frame_time}")

#anim <- data.plot +
#  transition_states(
#    country,
#    transition_length = 2,
#    state_length = 1
#  ) +
#  ease_aes

#data.plot + 
```

```{r}
temp.plot <- full.data |>
  mutate(year = as.numeric(year)) |>
  ggplot(mapping = aes(x = income,
                       y = sanitation)) +
  geom_point(show.legend = F) +
  transition_time(year) +
  labs(title = "Income versus Sanitation, 1999-2019",
       subtitle = "Year: {floor(frame_time)}",
       x = "Adjusted Income per Person (in 2017 $)",
       y = "Percentage of People with (at least) Basic Sanitation Services")
  
temp.plot
#we can make it so that the animation only play once, just didnt have time
```


Although the above scatter plot is very messy, we can see a general pattern: countries with low adjusted income per person have lower percentages of people with basic sanitation, whereas countries with high income per person never have less than 90 percent of people with basic sanitation.

However, there are instances where countries with very low income per person have high percentages of people with basic sanitation. Below you can see that the United States has had two years between 1999 and 2019 where adjusted income per person dipped below $20,000, but over 99% of Americans were able to have access to basic sanitation. 

```{r}
full.data |>
  mutate(year = as.numeric(year)) |>
  filter(country == "United States") |>
  ggplot(mapping = aes(x = income, y = sanitation)) +
  geom_point() +
  transition_time(year) +
  labs(title = "United States Income vs. Sanitation, 1999-2019",
       subtitle = "Year: {floor(frame_time)}",
       x = "Adjusted Income Per Person (in 2017 $)",
       y = "Percentage of People with (at least) Basic Santitation") +
  shadow_mark(alpha = 1, 
              size = 1)
```
Despite an obvious general trend, further investigation is needed to gain insight on descrepancies like the ones above.

### Relationship over Time:
We look at the relationship between average income per person and average percentage of people with basic sanitation at their disposal across 1999-2019.
```{r relation-over-time}
# take average income and sanitation for each year, then plot?
# cleveland dot plots to better indicate year
# 1999 is lowest, 2019 is highest, everything else already in order.
full.data |>
  group_by(year) |>
  summarise(mean_income = mean(income),
            mean_sanitation = mean(sanitation)) |>
  ggplot(mapping = aes(x = mean_income,
                       y = mean_sanitation#,
                       #color = fct_reorder2(year, mean_income, mean_sanitation)
                       )
         ) +
  geom_segment(mapping = aes(xend = 0, yend = mean_sanitation)) +
  geom_point() +
  annotate("text", x = 17000, y = 76.6, label = "2019") +
  annotate("text", x = 18700, y = 76.1, label = "2018") +
  annotate("text", x = 17600, y = 75.6, label = "2017") +
  annotate("text", x = 19200, y = 75.2, label = "2016") +
  annotate("text", x = 19200, y = 74.6, label = "2015") +
  annotate("text", x = 17500, y = 74.1, label = "2014") +
  annotate("text", x = 17000, y = 73.5, label = "2013") +
  annotate("text", x = 17700, y = 73.0, label = "2012") +
  annotate("text", x = 16900, y = 72.4, label = "2011") +
  annotate("text", x = 17500, y = 71.9, label = "2010") +
  annotate("text", x = 16100, y = 71.3, label = "2009") +
  annotate("text", x = 16600, y = 70.7, label = "2008") +
  annotate("text", x = 17200, y = 70.1, label = "2007") +
  annotate("text", x = 17200, y = 69.5, label = "2006") +
  annotate("text", x = 17200, y = 69, label = "2005") +
  annotate("text", x = 15900, y = 68.5, label = "2004") +
  annotate("text", x = 15200, y = 67.9, label = "2003") +
  annotate("text", x = 14700, y = 67.4, label = "2002") +
  annotate("text", x = 15000, y = 66.9, label = "2001") +
  annotate("text", x = 14400, y = 66.4, label = "2000") +
  annotate("text", x = 14600, y = 65.8, label = "1999") +
  labs(title = "Average Income versus Average Sanitation, 1999-2019",
       subtitle = "Average Percentage of People with Basic Sanitation",
       x = "Average Income per Person (in 2017 $)",
       y = "",
       color = "Year")
```

Plotting the aggregate average income per person and average sanitation percentage across all countries, the trend seems to follow a increasing trend. Again, further investigation (and possibly historical analysis) is required in order to decipher the dips in cleanliness around time frames such as the late 2000's and the early 2010's.

## Linear regression
```{r}
#| include = F
data.fit <- lm(sanitation~income, data = full.data)
summary(data.fit)
```
Upon fitting a simple linear regression model for percent of people who have access to basic sanitation ($Y$) based on adjusted income per person ($X$), we acquired the following regression equation:
$$\hat{Y} = 55.75 + 0.0009699X$$

Our regression equation tells us that a country with an average adjusted income of $0 will have 55.75% of its people with access to basic sanitation services. Further, for every ten thousand dollars increase in adjusted income per person, a country should expect a 9.699 percent increase in the amount of people who have access to basic sanitation.

## Model Fit

To assess the validity of our linear model, we look at the variances in observed sanitation percentage, predicted sanitation percentage, and residuals:

```{r}
model_var <- augment(data.fit) |>
  summarise(var.resp = var(sanitation),
         var.fitted = var(.fitted),
         var.resid =var(.resid))

model_var |>
  kable(caption = "Variance in Observed/Predicted/Residual Sanitation.",
        col.names = c("Variance in Sanitation", "Variance in Predicted", "Variance in Residuals"),
        align = c('l', 'l', 'l') )
```

The proportion of variability accounted for by our model was 0.333. Our model does a good enough job to communicate the general idea that more money means people are going to be cleaner. However, the variable we are hoping to predict is a percentage which means it can not exceed 100%, exposing the flaw that our model will predict impossible to reach sanitation percentages for high enough average income inputs. This gives us problems regarding what we can and can not conclude due to risk of extrapolating further than our data provides. There is not much we can do about this using a simple linear model as we would have to introduce a polynomial regression equation (say, through a logarithmic transformation) to be more precise.

# Simulation
```{r}
sanitation_lm <- lm(sanitation ~ income, data = full.data)
sanitation_predict <- predict(sanitation_lm)
head(sanitation_predict)

```
Pull Sigma = residual standard error
```{r}
san_sigma <- sigma(sanitation_lm)
san_sigma
```
Noise Function:
```{r}
noise <- function(x, mean = 0, sd){
  x + rnorm(length(x), 
            mean, 
            sd)
}
```
Simulated Response:
```{r}
sim_response <- tibble(sim_sanitation = noise(sanitation_predict, 
                                           sd = san_sigma)
                   )
head(sim_response)
```

